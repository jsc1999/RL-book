{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42c80673",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "348cfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Tuple, TypeVar, Sequence, List, Dict\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/Users/justincramer/Documents/Coding/CME241/RL-book/\"))\n",
    "import itertools\n",
    "from rl.distribution import Distribution, Choose\n",
    "from rl.function_approx import FunctionApprox, Tabular\n",
    "from rl.iterate import iterate\n",
    "from rl.markov_process import (FiniteMarkovRewardProcess, MarkovRewardProcess,\n",
    "                               RewardTransition, NonTerminal, State)\n",
    "from rl.markov_decision_process import (FiniteMarkovDecisionProcess,\n",
    "                                        MarkovDecisionProcess,\n",
    "                                        StateActionMapping)\n",
    "from rl.policy import DeterministicPolicy, FinitePolicy, FiniteDeterministicPolicy\n",
    "import rl.approximate_dynamic_programming\n",
    "from rl.approximate_dynamic_programming import evaluate_mrp, value_iteration, extended_vf, evaluate_finite_mrp\n",
    "from rl.dynamic_programming import policy_iteration as exact_policy_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1183493",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = TypeVar('S')\n",
    "A = TypeVar('A')\n",
    "\n",
    "# A representation of a value function for a finite MDP with states of\n",
    "# type S\n",
    "ValueFunctionApprox = FunctionApprox[NonTerminal[S]]\n",
    "QValueFunctionApprox = FunctionApprox[Tuple[NonTerminal[S], A]]\n",
    "NTStateDistribution = Distribution[NonTerminal[S]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b0b76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximate policy iteration\n",
    "def policy_iteration(\n",
    "    mdp: MarkovDecisionProcess[S, A],\n",
    "    γ: float,\n",
    "    approx_0: Tuple[ValueFunctionApprox[S], FinitePolicy[S, A]],\n",
    "    non_terminal_states_distribution: NTStateDistribution[S],\n",
    "    num_state_samples: int\n",
    ") -> Iterator[Tuple[ValueFunctionApprox[S], FinitePolicy[S, A]]]:\n",
    "    \n",
    "    def update(vf_policy: Tuple[ValueFunctionApprox[S], FinitePolicy[S, A]])\\\n",
    "            -> Tuple[ValueFunctionApprox[S], FiniteDeterministicPolicy[S, A]]:\n",
    "        vf, pi = vf_policy\n",
    "        print(pi)\n",
    "        # apply policy to get mrp\n",
    "        mrp: FiniteMarkovRewardProcess[S] = mdp.apply_finite_policy(pi)\n",
    "        vf_iter: Iterator[ValueFunctionApprox[S]] = evaluate_mrp(mrp, γ, vf, non_terminal_states_distribution, num_state_samples)\n",
    "        vf: ValueFunctionApprox[S] = list(itertools.islice(vf_iter, 200))[-1]        \n",
    "        \n",
    "        nt_states: Sequence[NonTerminal[S]] = \\\n",
    "            non_terminal_states_distribution.sample_n(num_state_samples)\n",
    "        \n",
    "        def return_(s_r: Tuple[State[S], float]) -> float:\n",
    "            s1, r = s_r\n",
    "            return r + γ * extended_vf(vf, s1)\n",
    "        \n",
    "        \n",
    "        d: Dict[S, A] = {s: max(mdp.actions(s), key=lambda a: mdp.step(s, a).expectation(return_)) for s in nt_states}\n",
    "        \n",
    "        pi: FiniteDeterministicPolicy[S, A] = FiniteDeterministicPolicy(d)\n",
    "        \n",
    "        return vf, pi\n",
    "    \n",
    "    v_0, pi_0 = approx_0\n",
    "    return iterate(update, (v_0, pi_0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
